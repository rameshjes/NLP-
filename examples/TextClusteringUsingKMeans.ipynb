{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Text Documents Using K-Means\n",
    "\n",
    "We use publicly available dataset consists of 20 news groups(categories). In order to perform k-means, we need to convert text into numbers, which is done with the help TF-IDF. TF-IDF determines the importance of the words based on its frequency. These features are fed to K-means algorithm to do clustering. In order to perform pre-processing, we use NLTK library for tokenization and lemmatization/stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "import string\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "\n",
    "Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "\n",
    "Equivalent to CountVectorizer followed by TfidfTransformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps \n",
    "\n",
    "## Stages: \n",
    "\n",
    "i. Pre-processing of the dataset\n",
    "\n",
    "ii. Creation of Term Document Matrix\n",
    "\n",
    "iii. TF-IDF (Term Frequency – Inverse Document Frequency) Normalization\n",
    "\n",
    "iv. K-Means Clustering using Euclidean Distances (sklearn by default uses Euclidean distances)\n",
    "\n",
    "v. Auto-Tagging based on Cluster Centers\n",
    "\n",
    "### Stage 1: (Pre-processing)\n",
    "\n",
    "i. Removing punctuations\n",
    "\n",
    "ii. Transforming to lower case\n",
    "\n",
    "iii. Grammatically tagging sentences and removing pre-identified stop phrases (Chunking)\n",
    "\n",
    "iv. Removing numbers from the document\n",
    "\n",
    "v. Stripping any excess white spaces\n",
    "\n",
    "\n",
    "vi. Removing generic words of the English language viz. determiners, articles, conjunctions and other parts of speech.\n",
    "\n",
    "vii. Document Stemming which reduces each word to its root using Porter’s stemming algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "training_set = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "target = training_set.target\n",
    "print len(training_set.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  targets\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...        7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...        4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...        4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...        1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...       14\n",
       "5  From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...       16\n",
       "6  From: bmdelane@quads.uchicago.edu (brian manni...       13\n",
       "7  From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...        3\n",
       "8  From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...        2\n",
       "9  From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...        4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(training_set.data, columns=[\"data\"])\n",
    "df[\"targets\"] = target\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>targets</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data\n",
       "targets      \n",
       "0         480\n",
       "1         584\n",
       "2         591\n",
       "3         590\n",
       "4         578\n",
       "5         593\n",
       "6         585\n",
       "7         594\n",
       "8         598\n",
       "9         597\n",
       "10        600\n",
       "11        595\n",
       "12        591\n",
       "13        594\n",
       "14        593\n",
       "15        599\n",
       "16        546\n",
       "17        564\n",
       "18        465\n",
       "19        377"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('targets').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print one sample of data\n",
    "print df[\"data\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization \n",
    "\n",
    "Since dataset contains many non-relevant words therefore we do pre-processing so that our algorithm can classify the data efficiently. \n",
    "\n",
    "### Pre-processing steps:\n",
    "\n",
    "i. Lemmatization / Stemming\n",
    "\n",
    "ii. Sentence Tokenization \n",
    "\n",
    "iii. Word Tokenization \n",
    "\n",
    "iv. Remove punctuations and contractions\n",
    "\n",
    "v. Apply Regex expressions to remove unwanted words(such as numbers i.e. A45 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class text_normalization:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.punctuations = list(punctuation)\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemma = WordNetLemmatizer()\n",
    "        self.contractions = {\"'nt\":\"not\", \"'ll\": \" will\",\"'d\":\"would\" ,\"'re\":\"are\", \"'ve\":\"have\", \"'m\":\"am\", \"'s\":\"is\"}\n",
    "        \n",
    "    '''\n",
    "    This function takes text as input \n",
    "    and returns list of tokenized words(punctuations not included) \n",
    "    '''    \n",
    "    def word_tokenizer(self,text):\n",
    "\n",
    "        self.word_tokenize_list = []\n",
    "        \n",
    "        for word in word_tokenize(text):\n",
    "            result = 0\n",
    "            #find words containing numbers i.e A45, or 45 \n",
    "            result = re.findall(r'([a-z]|[A-Z])(\\d)|(\\d)', word)\n",
    "\n",
    "            findUrl = re.findall(r'([a-z])(\\.com)', word)\n",
    "            \n",
    "            findBlankWords = re.findall(r'(([a-z])(__))|(__)([a-z])', word)\n",
    "            \n",
    "            findBlanks = re.findall(r'(__)', word)\n",
    "            \n",
    "            if word in self.contractions:\n",
    "\n",
    "                self.word_tokenize_list.append(self.contractions[word])\n",
    "            \n",
    "            elif len(findBlankWords) > 0 or len(findBlanks) > 0:\n",
    "                continue\n",
    "                \n",
    "            elif len(result) > 0:\n",
    "                continue\n",
    "                \n",
    "            elif len(findUrl) > 0:\n",
    "#                 print \"word \", word\n",
    "                continue\n",
    "                \n",
    "            elif len(word) < 3:\n",
    "                continue \n",
    "                \n",
    "            elif word in self.punctuations:\n",
    "                continue\n",
    "                \n",
    "            else: \n",
    "                self.word_tokenize_list.append(word)\n",
    "\n",
    "        return self.word_tokenize_list\n",
    "\n",
    "    '''\n",
    "    This function takes text as input \n",
    "    and returns list of tokenized sentences \n",
    "    '''    \n",
    "    def sentence_tokenizer(self,sentence):\n",
    "        \n",
    "        self.sentence_tokenize_list = sent_tokenize(sentence)        \n",
    "        return self.sentence_tokenize_list\n",
    "    \n",
    "    '''\n",
    "    This function takes tokenized sentence as input \n",
    "    and returns lemma of tokenized sentence \n",
    "    \n",
    "    1. First sentences from text are tokenized\n",
    "    2. Then, words from sentences are tokenized\n",
    "    3. Lemmatizer of words is determined\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def lemmatizer(self, sentences):\n",
    "        \n",
    "        sentences = re.sub(r'([a-z]|[A-Z])(_)', r'\\1', sentences)\n",
    "        sentences = re.sub(r'(_)([a-z]|[A-Z])', r'\\2', sentences)\n",
    "        \n",
    "        token_sent = self.sentence_tokenizer(sentences)\n",
    "        token_sent = token_sent[1:len(token_sent)-1]\n",
    "\n",
    "        token_word = [self.word_tokenizer(token_sent[i]) for i in range(len(token_sent))]\n",
    "        \n",
    "        lemmatizedSentences = []\n",
    "        \n",
    "        for noOfSent in range(len(token_word)):\n",
    "            stem = [(self.lemma.lemmatize((token_word[noOfSent][words]))) for words in range(len(token_word[noOfSent]))]\n",
    "            stem = \" \".join(stem)            \n",
    "            lemmatizedSentences.append(stem)\n",
    "           \n",
    "        lemmatizedSentences = \" \".join(lemmatizedSentences)\n",
    "        return lemmatizedSentences\n",
    "    \n",
    "    def porter_stemmer(self,sentence):\n",
    "        \n",
    "        token_sent = self.sentence_tokenizer(sentence)\n",
    "        token_word = [self.word_tokenizer(token_sent[i]) for i in range(len(token_sent))]\n",
    "        \n",
    "        stemizedSentences = []\n",
    "        \n",
    "        for no_of_sent in range(len(token_word)):\n",
    "            stem = [(self.stemmer.stem((token_word[no_of_sent][words]))) for words in range(len(token_word[no_of_sent]))]\n",
    "            stem = \" \".join(stem)\n",
    "            stemizedSentences.append(stem)\n",
    "            \n",
    "        stemizedSentences = \" \".join(stemizedSentences)\n",
    "        \n",
    "        return stemizedSentences\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe with two classes only\n",
    "\n",
    "Although there are 20 categories of the documents but for simplicity we just take documents of 2 categories. Furthermore, we only consider total 100 examples for the training and testing of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TwoClassesFrame = pd.DataFrame(columns=['examples', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examples</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: a137490@lehtori.cc.tut.fi (Aario Sami)\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: chrisb@seachg.com (Chris Blask)\\nSubject...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From:  (Rashid)\\nSubject: Re: Yet more Rushdie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: edb@dmssyd.syd.dms.CSIRO.AU (Ed Breen)\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: beck@irzr17.inf.tu-dresden.de (Andre Bec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: cjhs@minster.york.ac.uk\\nSubject: Re: fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: pallis@server.uwindsor.ca (PALLIS  DIMIT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From: joachim@kih.no (joachim lous)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From: bcash@crchh410.NoSubdomain.NoDomain (Bri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From: seth@north1.acpub.duke.edu (Seth Wanders...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From: jbrown@batman.bmd.trw.com\\nSubject: Re: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>From: weston@ucssun1.sdsu.edu (weston t)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From: thester@nyx.cs.du.edu (Uncle Fester)\\nSu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From: bryanw@rahul.net (Bryan Woodworth)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>From: johnsh@rpi.edu (Hugh Johnson)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Subject: XV under MS-DOS ?!?\\nFrom: NO E-MAIL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From: bcash@crchh410.NoSubdomain.NoDomain (Bri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From: andreasa@dhhalden.no (ANDREAS ARFF)\\nSub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From: dgraham@bmers30.bnr.ca (Douglas Graham)\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>From: ed@cwis.unomaha.edu (Ed Stastny)\\nSubjec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>From: weber@sipi.usc.edu (Allan G. Weber)\\nSub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>From: markus@octavia.anu.edu.au (Markus Buchho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>From: jonas-y@isy.liu.se (Jonas Yngvesson)\\nSu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>From: cbrasted@physics.adelaide.edu.au (Charle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>From: kshin@stein.u.washington.edu (Kevin Shin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>From: halat@pooh.bears (Jim Halat)\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>From: N020BA@tamvm1.tamu.edu\\nSubject: Help! N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>From: tdawson@engin.umich.edu (Chris Herringsh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>From: lpzsml@unicorn.nott.ac.uk (Steve Lang)\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>From: darice@yoyo.cc.monash.edu.au (Fred Rice)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>From: madhaus@netcom.com (Maddi Hausmann)\\nSub...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>From: luis.nobrega@filebank.cts.com (Luis Nobr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>From: dpw@sei.cmu.edu (David Wood)\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>From: davidk@welch.jhu.edu (David \"Go-Go\" Kita...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>From: sasst11+@pitt.edu (Scott A Snowiss)\\nSub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>From: stank@cbnewsl.cb.att.com (Stan Krieger)\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>From: bobbe@vice.ICO.TEK.COM (Robert Beauchain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>From: u895027@franklin.cc.utas.edu.au (Mark Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              examples labels\n",
       "0    From: jgreen@amber (Joe Green)\\nSubject: Re: W...      1\n",
       "1    From: mathew <mathew@mantis.co.uk>\\nSubject: R...      0\n",
       "2    From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...      1\n",
       "3    From: keith@cco.caltech.edu (Keith Allan Schne...      0\n",
       "4    From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...      1\n",
       "5    From: a137490@lehtori.cc.tut.fi (Aario Sami)\\n...      0\n",
       "6    From: chrisb@seachg.com (Chris Blask)\\nSubject...      0\n",
       "7    From:  (Rashid)\\nSubject: Re: Yet more Rushdie...      0\n",
       "8    From: edb@dmssyd.syd.dms.CSIRO.AU (Ed Breen)\\n...      1\n",
       "9    From: beck@irzr17.inf.tu-dresden.de (Andre Bec...      1\n",
       "10   From: cjhs@minster.york.ac.uk\\nSubject: Re: fr...      0\n",
       "11   From: tmc@spartan.ac.BrockU.CA (Tim Ciceran)\\n...      1\n",
       "12   From: pallis@server.uwindsor.ca (PALLIS  DIMIT...      1\n",
       "13   From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...      0\n",
       "14   From: joachim@kih.no (joachim lous)\\nSubject: ...      1\n",
       "15   From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec...      0\n",
       "16   From: bcash@crchh410.NoSubdomain.NoDomain (Bri...      0\n",
       "17   From: seth@north1.acpub.duke.edu (Seth Wanders...      1\n",
       "18   From: jbrown@batman.bmd.trw.com\\nSubject: Re: ...      0\n",
       "19   From: weston@ucssun1.sdsu.edu (weston t)\\nSubj...      1\n",
       "20   From: thester@nyx.cs.du.edu (Uncle Fester)\\nSu...      1\n",
       "21   From: bryanw@rahul.net (Bryan Woodworth)\\nSubj...      1\n",
       "22   From: johnsh@rpi.edu (Hugh Johnson)\\nSubject: ...      1\n",
       "23   Subject: XV under MS-DOS ?!?\\nFrom: NO E-MAIL ...      1\n",
       "24   From: bcash@crchh410.NoSubdomain.NoDomain (Bri...      0\n",
       "25   From: andreasa@dhhalden.no (ANDREAS ARFF)\\nSub...      1\n",
       "26   From: dgraham@bmers30.bnr.ca (Douglas Graham)\\...      0\n",
       "27   From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...      0\n",
       "28   From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...      0\n",
       "29   From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...      0\n",
       "..                                                 ...    ...\n",
       "71   From: ed@cwis.unomaha.edu (Ed Stastny)\\nSubjec...      1\n",
       "72   From: weber@sipi.usc.edu (Allan G. Weber)\\nSub...      1\n",
       "73   From: markus@octavia.anu.edu.au (Markus Buchho...      1\n",
       "74   From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka...      0\n",
       "75   From: jonas-y@isy.liu.se (Jonas Yngvesson)\\nSu...      1\n",
       "76   From: cbrasted@physics.adelaide.edu.au (Charle...      0\n",
       "77   From: kshin@stein.u.washington.edu (Kevin Shin...      1\n",
       "78   From: livesey@solntze.wpd.sgi.com (Jon Livesey...      0\n",
       "79   From: halat@pooh.bears (Jim Halat)\\nSubject: R...      0\n",
       "80   From: N020BA@tamvm1.tamu.edu\\nSubject: Help! N...      1\n",
       "81   From: tdawson@engin.umich.edu (Chris Herringsh...      1\n",
       "82   From: lpzsml@unicorn.nott.ac.uk (Steve Lang)\\n...      0\n",
       "83   From: keith@cco.caltech.edu (Keith Allan Schne...      0\n",
       "84   From: darice@yoyo.cc.monash.edu.au (Fred Rice)...      0\n",
       "85   From: madhaus@netcom.com (Maddi Hausmann)\\nSub...      0\n",
       "86   From: luis.nobrega@filebank.cts.com (Luis Nobr...      1\n",
       "87   From: dpw@sei.cmu.edu (David Wood)\\nSubject: R...      0\n",
       "88   From: davidk@welch.jhu.edu (David \"Go-Go\" Kita...      0\n",
       "89   From: keith@cco.caltech.edu (Keith Allan Schne...      0\n",
       "90   From: keith@cco.caltech.edu (Keith Allan Schne...      0\n",
       "91   From: sasst11+@pitt.edu (Scott A Snowiss)\\nSub...      1\n",
       "92   From: stank@cbnewsl.cb.att.com (Stan Krieger)\\...      0\n",
       "93   From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...      0\n",
       "94   From: mangoe@cs.umd.edu (Charley Wingate)\\nSub...      0\n",
       "95   From: bobbe@vice.ICO.TEK.COM (Robert Beauchain...      0\n",
       "96   From: jaeger@buphy.bu.edu (Gregg Jaeger)\\nSubj...      0\n",
       "97   From: healta@saturn.wwc.edu (Tammy R Healy)\\nS...      0\n",
       "98   From: kmr4@po.CWRU.edu (Keith M. Ryan)\\nSubjec...      0\n",
       "99   From: u895027@franklin.cc.utas.edu.au (Mark Ma...      1\n",
       "100  From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSub...      1\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i, t in df.iterrows():\n",
    "\n",
    "    if df[\"targets\"][i] < 2:\n",
    "#         print df['data'][i]\n",
    "        TwoClassesFrame.loc[count, 'examples'] = df['data'][i]\n",
    "        TwoClassesFrame.loc[count, 'labels'] = df['targets'][i]\n",
    "        count += 1\n",
    "        \n",
    "        if count > 100: \n",
    "            break\n",
    "    \n",
    "TwoClassesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TextNormalization = text_normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do prepreprocessing \n",
    "for row, name in TwoClassesFrame.iterrows():\n",
    "    \n",
    "    sentence = TwoClassesFrame.loc[row, 'examples']\n",
    "    TwoClassesFrame.loc[row, 'examples'] = TextNormalization.lemmatizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organization Harris Computer Systems Division Lines Distribution world NNTP-Posting-Host X-Newsreader TIN version Robert J.C. Kyanko rob rjck.UUCP wrote abraxis iastate.edu writes article Anyone know about the Weitek graphic chip far the low-level stuff go look pretty nice is got this quadrilateral fill command that requires just the four point you have Weitek is address/phone number would like get some information about this chip Joe Green Harris Corporation jgreen Computer Systems Division The only thing that really scare person with sense humor\n"
     ]
    }
   ],
   "source": [
    "# Print example after pre-processing\n",
    "print TwoClassesFrame[\"examples\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TwoClassesVectors = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "X_twoClasses = TwoClassesVectors.fit_transform(TwoClassesFrame[\"examples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the KMeans Model on the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=2, n_init=1, n_jobs=3, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 2\n",
    "model_twoClasses = KMeans(n_clusters=K, max_iter=100, n_init=1, n_jobs=3)\n",
    "model_twoClasses.fit(X_twoClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = (model_twoClasses.labels_)\n",
    "predicted = predicted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassified  20 Out of 101\n",
      "Total percentage of misclassification  19.801980198\n"
     ]
    }
   ],
   "source": [
    "true_labels = TwoClassesFrame[\"labels\"]\n",
    "true_labels = true_labels.tolist()\n",
    "misclassified = 0\n",
    "for i in range(len(predicted)):\n",
    "    \n",
    "    if predicted[i] != true_labels[i]:\n",
    "        misclassified += 1\n",
    "\n",
    "print \"misclassified \", str(misclassified) + \" Out of \" + str(len(true_labels))\n",
    "print \"Total percentage of misclassification \", (misclassified/len(true_labels))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52, 18],\n",
       "       [ 2, 29]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_Matrix = sklearn.metrics.confusion_matrix(predicted,true_labels)\n",
    "confusion_Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The total accuracy achieved is around 80% after evaluating on 2 categories from the news dataset. However, this performance can be increased if pre-processing can be further improved as some data contains lot of irrelevant information due to which algorithm fails to achieve optimal solution. \n",
    "\n",
    "This performance varies based on the initialization of K-means algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
